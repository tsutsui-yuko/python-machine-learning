##アルゴリズム

## 線形回帰  
点の群に最も近い位置を通る線形関数を導く。
目的関数を y = ax + b とし、実際に与えられる点をX,Yとすると (aX + b - Y)^2 が限りなく０に近づくように計算する。
これを最小二乗法という。
※二乗するのは絶対値で比較したいため

## リッジ回帰
線形回帰で最小化する目的関数に関数の定数パラメータ（上記の例だとa,b）の大きさの項（正則化項）を足したもの。
誤差を小さくするには、パラメータの大きさが小さいほうが良い。過学習を防ぐためのものらしい。
正則化項には定数λが掛けられる。λはハイパーパラメータ。定数パラメータの小ささをどの程度重視するかを表す。
線形回帰と比べて、サンプル数が少ない時に、例外的なデータからの影響が少なくなる。

## 用語  
- ハイパーパラメータ：モデルが学習を始める前にあらかじめ手動で決めておく値。
- チューニング：ハイパーパラメータの値を調整する。
- 多項式回帰：入力変数xに対して出力がxの多項式で表されるモデル。xが1次元の変数と考えると、2次以上の方程式で表されることになる。
